https://bizfluent.com/info-8367571-types-organizational-change-models.html


CHANGEMAKER COURSERA
  People need to understand WHY they're doing something uncomfortable and unpleasant
    This requires the changemaker to share that importance of the unrelated thing(s)
  Principles of human-centered design solutions
    1 stay focused - wicked challenges are nasty and easy to get distracted from
      Have a narrow frame of reference
      Dig deep, don't go broadly
    2 encourage wild ideas - Any idea, no matter how silly or wild or impossible, could be the start of something big
    3 have 1 conversation at a time - it creates focus on details
    4 defer judgment - no idea is bad when brainstorming
    5 be visual - use images to evoke feelings
      People take on what they FEEL
        Thus, adoption comes from feeling the benefit to doing that thing instead
        It's pushing against habit, so it has to be a strong feeling to work
  How to make a solution
    A understand
      This requires empathy
      Analyzing systems
        Who does what and how?
        Who decides what?
        Who gets what?
        Who connects to whom?
        Why are we doing what we're doing?
    B observe
    C create context
    D create ideas
    E prototype
      Must be 3 things:
        economically doable
        Technically doable
        People want it
      Exists with several main variables
        People - desires, reactions, etc
        Process - methods and systems
        Place - location, site, region, etc
    F test
      This requires several things to succeed
        Authenticity to own your mistakes
        Have a code of ethics that you abide by
        Clarify that it's ALL experimental (i.e., in constant beta




310 MGMT Blameless PostMortems and a Just Culture - Code as Craft
  Clipped from : https://codeascraft.com/2012/05/22/blameless-postmortems/
  Last week, Owen Thomas wrote a flattering article over at Business Insider on how we handle errors and mistakes at Etsy. I thought I might give some detail on how that actually happens, and why.
  Anyone who’s worked with technology at any scale is familiar with failure. Failure cares not about the architecture designs you slave over, the code you write and review, or the alerts and metrics you meticulously pore through.
  So: failure happens. This is a foregone conclusion when working with complex systems. But what about those failures that have resulted due to the actions (or lack of action, in some cases) of individuals? What do you do with those careless humans who caused everyone to have a bad day?
  Maybe they should be fired. Or maybe they need to be prevented from touching the dangerous bits again. Or maybe they need more training.
  This is the traditional view of “human error”, which focuses on the characteristics of the individuals involved. It’s what Sidney Dekker calls the “Bad Apple Theory” – get rid of the bad apples, and you’ll get rid of the human error. Seems simple, right?
  We don’t take this traditional view at Etsy. We instead want to view mistakes, errors, slips, lapses, etc. with a perspective of learning. Having blameless Post-Mortems on outages and accidents are part of that.
  A Blameless Post-Mortem
  What does it mean to have a ‘blameless’ Post-Mortem?
  Does it mean everyone gets off the hook for making mistakes? No.
  Well, maybe. It depends on what “gets off the hook” means. Let me explain.
  Having a Just Culture means that you’re making effort to balance safety and accountability. It means that by investigating mistakes in a way that focuses on the situational aspects of a failure’s mechanism and the decision-making process of individuals proximate to the failure, an organization can come out safer than it would normally be if it had simply punished the actors involved as a remediation.
  Having a “blameless” Post-Mortem process means that engineers whose actions have contributed to an accident can give a detailed account of:
    • what actions they took at what time,
    • what effects they observed,
    • expectations they had,
    • assumptions they had made,
    • and their understanding of timeline of events as they occurred.
  …and that they can give this detailed account without fear of punishment or retribution.
  Why shouldn’t they be punished or reprimanded? Because an engineer who thinks they’re going to be reprimanded are disincentivized to give the details necessary to get an understanding of the mechanism, pathology, and operation of the failure. This lack of understanding of how the accident occurred all but guarantees that it will repeat. If not with the original engineer, another one in the future.
  We believe that this detail is paramount to improving safety at Etsy.
  If we go with “blame” as the predominant approach, then we’re implicitly accepting that deterrence is how organizations become safer. This is founded in the belief that individuals, not situations, cause errors. It’s also aligned with the idea there has to be some fear that not doing one’s job correctly could lead to punishment. Because the fear of punishment will motivate people to act correctly in the future. Right?
  This cycle of name/blame/shame can be looked at like this:
    1. Engineer takes action and contributes to a failure or incident.
    2. Engineer is punished, shamed, blamed, or retrained.
    3. Reduced trust between engineers on the ground (the “sharp end”) and management (the “blunt end”) looking for someone to scapegoat
    4. Engineers become silent on details about actions/situations/observations, resulting in “Cover-Your-Ass” engineering (from fear of punishment)
    5. Management becomes less aware and informed on how work is being performed day to day, and engineers become less educated on lurking or latent conditions for failure due to silence mentioned in #4, above
    6. Errors more likely, latent conditions can’t be identified due to #5, above
    7. Repeat from step 1
  We need to avoid this cycle. We want the engineer who has made an error give details about why (either explicitly or implicitly) he or she did what they did; why the action made sense to them at the time. This is paramount to understanding the pathology of the failure. The action made sense to the person at the time they took it, because if it hadn’t made sense to them at the time, they wouldn’t have taken the action in the first place.
  The base fundamental here is something Erik Hollnagel has said:
    We must strive to understand that accidents don’t happen because people gamble and lose.
    Accidents happen because the person believes that:
    …what is about to happen is not possible,
    …or what is about to happen has no connection to what they are doing,
    …or that the possibility of getting the intended outcome is well worth whatever risk there is.
  A Second Story
  This idea of digging deeper into the circumstance and environment that an engineer found themselves in is called looking for the “Second Story”. In Post-Mortem meetings, we want to find Second Stories to help understand what went wrong.
  From Behind Human Error here’s the difference between “first” and “second” stories of human error:
  First Stories	Second Stories
  Human error is seen as cause of failure	Human error is seen as the effect of systemic vulnerabilities deeper inside the organization
  Saying what people should have done is a satisfying way to describe failure	Saying what people should have done doesn’t explain why it made sense for them to do what they did
  Telling people to be more careful will make the problem go away	Only by constantly seeking out its vulnerabilities can organizations enhance safety
    Allowing Engineers to Own Their Own Stories
  A funny thing happens when engineers make mistakes and feel safe when giving details about it: they are not only willing to be held accountable, they are also enthusiastic in helping the rest of the company avoid the same error in the future. They are, after all, the most expert in their own error. They ought to be heavily involved in coming up with remediation items.
  So technically, engineers are not at all “off the hook” with a blameless PostMortem process. They are very much on the hook for helping Etsy become safer and more resilient, in the end. And lo and behold: most engineers I know find this idea of making things better for others a worthwhile exercise.
  So what do we do to enable a “Just Culture” at Etsy?
    • We encourage learning by having these blameless Post-Mortems on outages and accidents.
    • The goal is to understand how an accident could have happened, in order to better equip ourselves from it happening in the future
    • We seek out Second Stories, gather details from multiple perspectives on failures, and we don’t punish people for making mistakes.
    • Instead of punishing engineers, we instead give them the requisite authority to improve safety by allowing them to give detailed accounts of their contributions to failures.
    • We enable and encourage people who do make mistakes to be the experts on educating the rest of the organization how not to make them in the future.
    • We accept that there is always a discretionary space where humans can decide to make actions or not, and that the judgement of those decisions lie in hindsight.
    • We accept that the Hindsight Bias will continue to cloud our assessment of past events, and work hard to eliminate it.
    • We accept that the Fundamental Attribution Error is also difficult to escape, so we focus on the environment and circumstances people are working in when investigating accidents.
    • We strive to make sure that the blunt end of the organization understands how work is actually getting done (as opposed to how they imagine it’s getting done, via Gantt charts and procedures) on the sharp end.
    • The sharp end is relied upon to inform the organization where the line is between appropriate and inappropriate behavior. This isn’t something that the blunt end can come up with on its own.
  Failure happens. In order to understand how failures happen, we first have to understand our reactions to failure.
  One option is to assume the single cause is incompetence and scream at engineers to make them “pay attention!” or “be more careful!”
  Another option is to take a hard look at how the accident actually happened, treat the engineers involved with respect, and learn from the event.
  That’s why we have blameless Post-Mortems at Etsy, and why we’re looking to create a Just Culture here.









https://apenwarr.ca/log/20190926
  What do executives do, anyway?
  An executive with 8,000 indirect reports and 2000 hours of work in a year can afford to spend, at most, 15 minutes per year per person in their reporting hierarchy... even if they work on nothing else. That job seems impossible. How can anyone make any important decision in a company that large? They will always be the least informed person in the room, no matter what the topic.
  If you know me, you know I've been asking myself this question for a long time.
  Luckily, someone sent me a link to a really great book, High Output Management, by Andy Grove (of Intel fame). Among many other things, it answers this key question! And insultingly, just to rub it in, it answered this question back in the 1980s.
  To paraphrase the book, the job of an executive is: to define and enforce culture and values for their whole organization, and to ratify good decisions.
  That's all.
  Not to decide. Not to break ties. Not to set strategy. Not to be the expert on every, or any topic. Just to sit in the room while the right people make good decisions in alignment with their values. And if they do, to endorse it. And if they don't, to send them back to try again.
  There's even an algorithm for this.
  It seems too easy to be real. For any disagreement, identify the lead person on each side. Then, identify the lowest executive in the corporate hierarchy that both leads report into (in the extreme case, this is the CEO). Set up a meeting between the three of them. At the meeting, the two leads will present the one, correct decision that they have agreed upon. The executive will sit there, listen, and ratify it.
  But... wait. If the decision is already made before the meeting, why do we need the meeting? Because the right decision might not happen without the existence of that meeting. The executive gives formal weight to a major decision. The executive holds the two disagreeing leads responsible: they must figure out not what's best for them, but what's best for the company. They can't pull rank. They can't cheat. They have to present their answer to a person who cares about both of their groups equally. And they want to look good, because that person is their boss! This puts a lot of pressure on people to do the right thing.
  (Side note: this has parallels with the weirdly formal structures in eg. Canadian parliament, where theoretically all decisions must be ratified by the seemingly powerless Governor General, who represents The Queen by just always ratifying everything. The theory is that if the decisions were bad, they wouldn't be ratified, so there'd be no point proposing them, and therefore all the decisions proposed are worthy of ratification. Obviously the theory doesn't match the practice here, because bad decisions get ratified, but it's nice to think about.)
  Failure modes
  What happens when an executive doesn't follow this model? One of several things we've all seen before, depending what the executive does instead.
    If the executive makes their own decisions and forces them downstream: the executive doesn't have enough information to make good decisions in detail, so the decision won't be optimal. And there won't be much buy-in from people downstream. This also encourages politics: people whisper in the executive's ear to bend it one way or the other. It encourages "brown-nosing."
    If the executive chooses not to be involved in conflicts that are "not important enough; you figure it out": political power games ensue. Whoever can force their way will win, killing morale. Or half the people do one thing and half do the other, and the company loses focus.
    If the executive accepts escalations, then tries to make a tie-breaker decision: non-optimal decisions get made, because again the executive is, out of the three people, the least qualified to decide. Offhand, you might think this is fine, if the decision isn't very important anyway. That part is true. But the indirect effects are disastrous: it allows the two leads to abdicate resonsibility. They don't have to remind themselves what's good for the company, because you did it for them. It lets them be selfish. It lets disagreement fester. It leaves at least one side not fully bought in.
    (I'm wary of "disagree and commit" for this reason. Real people don't commit when they strongly disagree; they only pretend to. In service of a value like "move fast and break things" it can work, because speed overrides wisdom or consistency. That's a legitimate value, like any other, if it serves your strategy.)
    If the executive brings in more people to discuss the issue: this is something the two leads should have done already. If they didn't, they are failing at their job, and need to learn how to do it better. Step one is the executive sends them a message: "Go back. Include these additional people/groups in your decision. Come back when you've thought it through properly." If it continues, people have to get fired, because they are bad at making decisions.
  Enforcement of culture and values
  According to the book, which makes a pretty compelling case, the only other responsibility of an executive is to enforce company values.
  What does that mean? It means if someone in the company isn't acting "right" - not acting ethically, not following the conflict resolution algorithm above, playing politics - then they need to be corrected or removed. Every executive is responsible for enforcing the policy all the way down the chain, recursively. And the CEO is responsible for everyone. You have to squash violators of company values, fast, because violators are dangerous. People who don't share your values will hire more people who don't share your values. It's all downhill from there.
  Real values aren't what you talk about, they're what you do when times get tough. That means values are most visible during big, controversial decisions. The executive ratifying a decision needs to evaluate that decision against the set of organizational values. Do the two leads both understand our values? Is the decision in line with our values? If not, tell them so, explicitly, and send them back to try again.
  What about strategy?
  One of the book's claims, which I found shocking at first, was that in a large organization, executives don't set strategy. Not even the CEO sets strategy. Why? Because it's an illusion to believe you can enforce a strategy.
  Employees, including executives that report to you, follow company values first and foremost. (This is by definition construction. If they don't, you fired them, see above.) Of course, they're human, so as part of that, they'll be looking out for themselves, their friends, and the people in their organization.
  Maybe one of your organizational values is "do what your boss says." That's a thing you can do, and you can enforce. It works. The military works like that supposedly (although I have no experience with the military). But command-and-control is not very efficient for knowledge workers, because of the fundamental problem that for any given situation, the people who know the most about it are the people at the bottom, not the people at the top.
  If the people at the bottom can't agree what to do, then great! That's why we have a hierarchy. Use the decision process above until the answer is obvious.
  But if the person at the top is trying to "set a strategy" by making operational decisions, those decisions will be based on insufficient facts, because there are simply far too many facts for one person. That means, if your decisions should be based on facts, you will make worse decisions than your subordinates. That's scary.
  So what, then? A company just drifts in the void, with no strategy?
  Not exactly. It's harder than that. What executives need to do is come up with organizational values that indirectly result in the strategy they want.
  That is, if your company makes widgets and one of your values is customer satisfaction, you will probably end up with better widgets of the right sort for your existing customers. If one of your values is to be environmentally friendly, your widget factories will probably pollute less but cost more. If one of your values is to make the tools that run faster and smoother, your employees will probably make less bloatware and you'll probably hire different employees than if your values are to scale fast and capture the most customers in the shortest time.
  Why will employees embrace whatever weird organizational values you set? Because in every decision meeting, you enforce your values. And you fire the people who don't line up. Recursively, that means executives lower down the tree will do the same, because that itself is one of the values you enforce.
  Unless it's somehow impossible to hire people who agree with your values, you can assemble an organization that aligns with them. It might be a terrible organization that ruins your business, but then... well, those values weren't a good choice.
  I can't believe nobody told me this before. It's all so simple, and it's all been documented since the 1980s.
  Epilogue: small companies
  Almost none of this applies to small companies. They are so small that the founders and the CEO actually do have a chance of fully understanding problems, which means they don't yet need to delegate decisions. Also, in a small company, strategy and values are usually not well defined yet, so a primary goal is to discover them incrementally. You learn from mistakes and refine together until the strategy (and thus the values that will produce the strategy) become clear.
  In a small company, it's important to understand how the big company process works, because your values begin to solidify pretty early on, even as you choose co-founders and investors and hire the first employees. It's hard to change your values later, because it usually involves firing people. So you need to be thinking about them from the beginning. Still, the details aren't set in stone on day 1.
  Doubilogue: major strategic changes
  All this is one reason why if you want a major strategic change, you often replace an executive - maybe even the CEO. Or, conversely, if you replace the CEO, you often get a major strategic change, whether you like it or not. The CEO sets the values, and the values set the strategy.
  Company values flow downward. They are very hard to change, and very painful. When you change your company values, you might find that employees who liked the old values don't want to work there anymore, and rightly so. (This happens even if the new values are "better" in your favourite dimensions.)
  If your old strategy is failing, you can't fix the company by just declaring a new strategy. You do it by declaring new values. Then you enforce those values. And that's going to make a lot of people very upset. (If you do this too often, you deserve what you get.)
  One reason strategy changes are so risky in a big company is that, again, the people at the top really don't know much of what's going on. Although they have a sky-high view of the world, they have a very limited view of the details. Changes of strategy, and therefore changes of values, and therefore changes of executives, usually have wide-ranging unexpected consequences. You do it because you have to, because your old strategy isn't working, not because you want to. You're betting everything.
  I wish more executives would be transparent about this. "Our old strategy wasn't working, because our old values weren't working. Here's the new strategy, and the new values. This is gonna hurt."
  What you usually get instead is a polite "rewording" or "watering down" of the corporate values, and maybe some whispering about how the old values weren't so good after all, and maybe how the new values were our real values all along. Weak.
  Or, worst of all, executives lose their way and stop enforcing any value system at all. Then the value system reverts to the default: politics and backstabbing. It wouldn't bother me so much if it weren't so hopelessly inefficient.
  Tripilogue: governments
  Governmental politics are bad exactly to the extent that we don't enforce our values by firing the people who don't encompass them.
  In a democracy, this is hard because values in the first place are agreed by mass consensus rather than chosen at the top. That's why propaganda is so powerful: it changes our values, which changes who and what we tolerate.
  Quadrilogue: Tradeoffs
  By the way, useful organizational values come in the form of tradeoffs: giving up one nice thing in order to get some other nice thing. Wishy-washy values like "respect your co-workers" aren't really values, because nobody would ever pick a value like "don't respect your co-workers." Respecting your co-workers is just basic civility. By the time you have to write it down, you've already lost. Put it in your HR policy somewhere, not the top line.
  A real value is something like "tell the truth, even when it hurts." Or "deliver the software on schedule, even if there are bugs." In both cases, one can legitimately imagine valuing the opposite.
  Related 
  An epic treatise on scheduling, bug tracking, and triage (2017)
  Smallness, responsiveness, feedback (2006)
  Unrelated 
  Hmm (2013)
  My new project is Tailscale:
  ssh+2FA to all your machines, anywhere, without opening firewall ports.
  Why would you follow me on twitter? Use RSS.
  apenwarr-on-gmail.com





Whenever a control/check/restriction is put in place
  A consider its COSTS along with its benefits
  B imagine all the people who would be most adversely affected by the change
There are 2 major issues to watch for in censoring bad actors
  Bad originators from leaders
    This is things like someone making a comment or public expression that doesn't reflect the values of the organization
  Bad responses from followers
    This is things like comments and smaller discussion that take place IN RESPONSE TO a big statement from a leader
