{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Specific Handwritten Digit Using CGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just learned how CGAN works and the architecture of CGAN. To strengthen our understanding, now we will learn how to implement CGAN in TensorFlow for generating an image of specific handwritten digit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries\n",
    "\n",
    "First, we will import all the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "tf.reset_default_graph()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the Dataset\n",
    "\n",
    "Load the MNIST dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "data = input_data.read_data_sets(\"data/mnist\",one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Generator \n",
    "\n",
    "Generator $G$ takes the noise $z$ and also the conditional variable $c$ as an input and returns an image. We define the generator as a simple 2 layer feed forward network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z, c,reuse=False):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        \n",
    "        #initialize weights\n",
    "        w_init = tf.contrib.layers.xavier_initializer()\n",
    "        \n",
    "        #concatenate noize z and conditional  variable c to form an input\n",
    "        inputs = tf.concat([z, c], 1)\n",
    "        \n",
    "        #define the first layer with relu activation\n",
    "        dense1 = tf.layers.dense(inputs, 128, kernel_initializer=w_init)\n",
    "        relu1 = tf.nn.relu(dense1)\n",
    "        \n",
    "        #define the second layer and compute the output using the tanh activation function\n",
    "        logits = tf.layers.dense(relu1, 784, kernel_initializer=w_init)\n",
    "        output = tf.nn.tanh(logits)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Discriminator\n",
    "\n",
    "We know that discriminator $D$ returns the probability. i.e it will tell us the probability of the given image being real. Along with the input image $x$, it also takes the conditional varaible $c$ as an input. We define the discriminator also as a simple 2 layer feed forward network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(x, c, reuse=False):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        \n",
    "        #initialize weights\n",
    "        w_init = tf.contrib.layers.xavier_initializer()\n",
    "        \n",
    "        #concatenate noize z and conditional variable c to form an input\n",
    "        inputs = tf.concat([x, c], 1)\n",
    "    \n",
    "        #define the first layer with the relu activation\n",
    "        dense1 = tf.layers.dense(inputs, 128, kernel_initializer=w_init)\n",
    "        relu1 = tf.nn.relu(dense1)\n",
    "        \n",
    "        #define the second layer and compute the output using sigmoid activation function\n",
    "        logits = tf.layers.dense(relu1, 1, kernel_initializer=w_init)\n",
    "        output = tf.nn.sigmoid(logits)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the input placeholders\n",
    "\n",
    "\n",
    "Now, we define the placeholder for the input $x$, conditional variable $c$ and the noise $z$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=(None, 784))\n",
    "c = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "z = tf.placeholder(tf.float32, shape=(None, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the GAN!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we feed the noise z to the generator and it will output the fake image. i.e $ fake \\; x = G(z|c) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_x = generator(z, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we feed the real image $x$ along with conditional variable $c$ to the discriminator $D(x|c)$ and get the probabillty of being real:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_logits_real = discriminator(x,c) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we feed the fake image fake_x and conditional variable $c$ to the discirminator $D(z|c)$ and get the probabillty of it being real:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_logits_fake = discriminator(fake_x, c, reuse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Loss Function\n",
    "\n",
    "Now, we will see, how to compute the loss function. It is essentially same as vanilla GAN except that we add a condtional variable. \n",
    "\n",
    "\n",
    "\n",
    "### Discriminator Loss\n",
    "\n",
    "Discriminator loss is given as,\n",
    "\n",
    "${L ^{D} =  - \\mathbb{E}_{x \\sim p_{r}(x)}[\\log D(x|c)] - \\mathbb{E}_{z \\sim p_{z}(z)}[\\log (1-D(G(z|c))]} $\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "First we will implement the first term i.e $\\mathbb{E}_{x \\sim p_{r}(x)}[\\log D(x|c)]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logits_real,\n",
    "                                                                     labels=tf.ones_like(D_logits_real)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the second term, $\\mathbb{E}_{z \\sim p_{z}(z)}[\\log (1-D(G(z|c))]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logits_fake,\n",
    "                                                                     labels=tf.zeros_like(D_logits_fake)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final loss can be written as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_loss = D_loss_real + D_loss_fake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Loss\n",
    "\n",
    "Generator loss is given as:\n",
    "\n",
    "${L^{G}= - \\mathbb{E}_{z \\sim p_{z}(z)}[\\log (D(G(z|c)))] } $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logits_fake,\n",
    "                                                                labels=tf.ones_like(D_logits_fake)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing the Loss\n",
    "\n",
    "\n",
    "Now we need to optimize our generator and discriminator. So, we collect the parameters of the discriminator and generator as $\\theta_D$ and $\\theta_G$ respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_vars = tf.trainable_variables()\n",
    "theta_D = [var for var in training_vars if var.name.startswith('discriminator')]\n",
    "theta_G = [var for var in training_vars if var.name.startswith('generator')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize the loss using adam optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_optimizer = tf.train.AdamOptimizer(0.001, beta1=0.5).minimize(D_loss, var_list=theta_D)\n",
    "G_optimizer = tf.train.AdamOptimizer(0.001, beta1=0.5).minimize(G_loss, var_list=theta_G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the Training \n",
    "\n",
    "\n",
    "Start the TensorFlow session and initialize variables:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the batch size, number of epochs and number of classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_epochs = 5000\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the images and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = data.train.images\n",
    "labels = data.train.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Handwritten Digit 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the digit to generate as 7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_generate = 7\n",
    "onehot = np.eye(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for i in range(len(images) // batch_size):\n",
    "        \n",
    "        #sample images\n",
    "        batch_image = images[i * batch_size:(i + 1) * batch_size]\n",
    "        \n",
    "        #sample the condition that is, digit we want to generate\n",
    "        batch_c = labels[i * batch_size:(i + 1) * batch_size]\n",
    "        \n",
    "        #sample noise\n",
    "        batch_noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        \n",
    "        #train the generator\n",
    "        generator_loss, _ = session.run([D_loss, D_optimizer], {x: batch_image, c: batch_c, z: batch_noise})\n",
    "           \n",
    "        #train the discriminator\n",
    "        discriminator_loss, _ = session.run([G_loss, G_optimizer],  {x: batch_image, c: batch_c, z: batch_noise})\n",
    "    \n",
    "    #sample noise\n",
    "    noise = np.random.rand(1,100)\n",
    "    \n",
    "    #select specific digit\n",
    "    gen_label = np.array([[label_to_generate]]).reshape(-1)\n",
    "    \n",
    "    #convert the selected digit\n",
    "    one_hot_targets = np.eye(num_classes)[gen_label]\n",
    "    \n",
    "    #Feed the noise and one hot encoded condition to the generator and generate the fake image\n",
    "    _fake_x = session.run(fake_x, {z: noise, c: one_hot_targets})\n",
    "    _fake_x = _fake_x.reshape(28,28)\n",
    "    \n",
    "   \n",
    "    \n",
    "    print(\"Epoch: {},Discriminator Loss:{}, Generator Loss: {}\".format(epoch,discriminator_loss,generator_loss))\n",
    "    \n",
    "    #plot the generated image\n",
    "    display.clear_output(wait=True)\n",
    "    plt.imshow(_fake_x) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, with CGAN we can generate a speific image that we want to generate. In the next section, we will learn about InfoGAN which is the unsupervised version of CGAN."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
