{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building your own Chatbot\n",
    "\n",
    "## Why should I build the service again? \n",
    "\n",
    "##### Related: Why can't I use FB/MSFT/some other cloud service?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Vectors + Heuristic - Fancy Stuff = Quick Working Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gensim version: 3.4.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gensim\n",
    "print(f\"Gensim version: {gensim.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, please remove if you wish to download again\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "class TqdmUpTo(tqdm):\n",
    "    def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        if tsize is not None: self.total = tsize\n",
    "        self.update(b * bsize - self.n)\n",
    "\n",
    "def get_data(url, filename):\n",
    "    \"\"\"\n",
    "    Download data if the filename does not exist already\n",
    "    Uses Tqdm to show download progress\n",
    "    \"\"\"\n",
    "    import os\n",
    "    from urllib.request import urlretrieve\n",
    "    \n",
    "    if not os.path.exists(filename):\n",
    "\n",
    "        dirname = os.path.dirname(filename)\n",
    "        if not os.path.exists(dirname):\n",
    "            os.makedirs(dirname)\n",
    "\n",
    "        with TqdmUpTo(unit='B', unit_scale=True, miniters=1, desc=url.split('/')[-1]) as t:\n",
    "            urlretrieve(url, filename, reporthook=t.update_to)\n",
    "    else:\n",
    "        print(\"File already exists, please remove if you wish to download again\")\n",
    "\n",
    "embedding_url = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
    "get_data(embedding_url, 'data/glove.6B.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip data/glove.6B.zip \n",
    "# !mv -v glove.6B.300d.txt data/glove.6B.300d.txt \n",
    "# !mv -v glove.6B.200d.txt data/glove.6B.200d.txt \n",
    "# !mv -v glove.6B.100d.txt data/glove.6B.100d.txt \n",
    "# !mv -v glove.6B.50d.txt data/glove.6B.50d.txt \n",
    "\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove_input_file = 'data/glove.6B.300d.txt'\n",
    "word2vec_output_file = 'data/glove.6B.300d.txt.word2vec'\n",
    "import os\n",
    "if not os.path.exists(word2vec_output_file):\n",
    "    glove2word2vec(glove_input_file, word2vec_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 49s, sys: 2.11 s, total: 1min 51s\n",
      "Wall time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from gensim.models import KeyedVectors\n",
    "filename = word2vec_output_file\n",
    "embed = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert embed['awesome'] is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'awesome', this works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case: Food Order Bot\n",
    "\n",
    "### Do word vectors even work for this? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_refs = [\"mexican\", \"thai\", \"british\", \"american\", \"italian\"]\n",
    "sample_sentence = \"Iâ€™m looking for a cheap Indian or Chinese place in Indiranagar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking: 7.448504447937012\n",
      "for: 10.627421379089355\n",
      "a: 11.809560775756836\n",
      "cheap: 7.09670877456665\n",
      "indian: 18.64516258239746\n",
      "or: 9.692893981933594\n",
      "chinese: 19.09498405456543\n",
      "place: 7.651237487792969\n",
      "in: 10.085711479187012\n",
      "['indian', 'chinese']\n"
     ]
    }
   ],
   "source": [
    "tokens = sample_sentence.split()\n",
    "tokens = [x.lower().strip() for x in tokens] \n",
    "threshold = 18.3\n",
    "found = []\n",
    "for term in tokens:\n",
    "    if term in embed.vocab:\n",
    "        scores = []\n",
    "        for C in cuisine_refs:\n",
    "            scores.append(np.dot(embed[C], embed[term].T))\n",
    "            # hint replace above above np.dot with: \n",
    "            # scores.append(embed.cosine_similarities(<vector1>, <vector_all_others>))\n",
    "        mean_score = np.mean(scores)\n",
    "        print(f\"{term}: {mean_score}\")\n",
    "        if mean_score > threshold:\n",
    "            found.append(term)\n",
    "print(found)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Stop: Classifying user intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "def sum_vecs(embed,text):\n",
    "\n",
    "    tokens = text.split(' ')\n",
    "    vec = np.zeros(embed.vector_size)\n",
    "\n",
    "    for idx, term in enumerate(tokens):\n",
    "        if term in embed.vocab:\n",
    "            vec = vec + embed[term]\n",
    "    return vec\n",
    "\n",
    "sentence_vector = sum_vecs(embed, sample_sentence)\n",
    "print(sentence_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={\n",
    "  \"greet\": {\n",
    "    \"examples\" : [\"hello\",\"hey there\",\"howdy\",\"hello\",\"hi\",\"hey\",\"hey ho\"],\n",
    "    \"centroid\" : None\n",
    "  },\n",
    "  \"inform\": {\n",
    "    \"examples\" : [\n",
    "        \"i'd like something asian\",\n",
    "        \"maybe korean\",\n",
    "        \"what mexican options do i have\",\n",
    "        \"what italian options do i have\",\n",
    "        \"i want korean food\",\n",
    "        \"i want german food\",\n",
    "        \"i want vegetarian food\",\n",
    "        \"i would like chinese food\",\n",
    "        \"i would like indian food\",\n",
    "        \"what japanese options do i have\",\n",
    "        \"korean please\",\n",
    "        \"what about indian\",\n",
    "        \"i want some chicken\",\n",
    "        \"maybe thai\",\n",
    "        \"i'd like something vegetarian\",\n",
    "        \"show me french restaurants\",\n",
    "        \"show me a cool malaysian spot\",\n",
    "        \"where can I get some spicy food\"\n",
    "    ],\n",
    "    \"centroid\" : None\n",
    "  },\n",
    "  \"deny\": {\n",
    "    \"examples\" : [\n",
    "      \"nah\",\n",
    "      \"any other places ?\",\n",
    "      \"anything else\",\n",
    "      \"no thanks\"\n",
    "      \"not that one\",\n",
    "      \"i do not like that place\",\n",
    "      \"something else please\",\n",
    "      \"no please show other options\"\n",
    "    ],\n",
    "    \"centroid\" : None\n",
    "  },\n",
    "    \"affirm\":{\n",
    "        \"examples\":[\n",
    "            \"yeah\",\n",
    "            \"that works\",\n",
    "            \"good, thanks\",\n",
    "            \"this works\",\n",
    "            \"sounds good\",\n",
    "            \"thanks, this is perfect\",\n",
    "            \"just what I wanted\"\n",
    "        ],\n",
    "        \"centroid\": None\n",
    "    }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroid(embed, examples):\n",
    "    C = np.zeros((len(examples),embed.vector_size))\n",
    "    for idx, text in enumerate(examples):\n",
    "        C[idx,:] = sum_vecs(embed,text)\n",
    "\n",
    "    centroid = np.mean(C,axis=0)\n",
    "    assert centroid.shape[0] == embed.vector_size\n",
    "    return centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Centroid to data dictionary\n",
    "for label in data.keys():\n",
    "    data[label][\"centroid\"] = get_centroid(embed,data[label][\"examples\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greet: ['hello', 'hey there', 'howdy', 'hello', 'hi', 'hey', 'hey ho']\n",
      "inform: [\"i'd like something asian\", 'maybe korean', 'what mexican options do i have', 'what italian options do i have', 'i want korean food', 'i want german food', 'i want vegetarian food', 'i would like chinese food', 'i would like indian food', 'what japanese options do i have', 'korean please', 'what about indian', 'i want some chicken', 'maybe thai', \"i'd like something vegetarian\", 'show me french restaurants', 'show me a cool malaysian spot', 'where can I get some spicy food']\n",
      "deny: ['nah', 'any other places ?', 'anything else', 'no thanksnot that one', 'i do not like that place', 'something else please', 'no please show other options']\n",
      "affirm: ['yeah', 'that works', 'good, thanks', 'this works', 'sounds good', 'thanks, this is perfect', 'just what I wanted']\n"
     ]
    }
   ],
   "source": [
    "for label in data.keys():\n",
    "    print(f\"{label}: {data[label]['examples']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intent(embed,data, text):\n",
    "    intents = list(data.keys())\n",
    "    vec = sum_vecs(embed,text)\n",
    "    scores = np.array([ np.linalg.norm(vec-data[label][\"centroid\"]) for label in intents])\n",
    "    return intents[np.argmin(scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text : 'hey ', predicted_label : 'greet'\n",
      "text : 'i am looking for chinese food', predicted_label : 'inform'\n",
      "text : 'not for me', predicted_label : 'deny'\n",
      "text : 'ok, this is good', predicted_label : 'affirm'\n"
     ]
    }
   ],
   "source": [
    "for text in [\"hey \",\"i am looking for chinese food\",\"not for me\", \"ok, this is good\"]:\n",
    "    print(f\"text : '{text}', predicted_label : '{get_intent(embed, data, text)}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bot Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = {\n",
    "        \"utter_greet\": [\"hey there!\", \"Hey! How you doin'? \"],\n",
    "        \"utter_options\": [\"ok, let me check some more\"],\n",
    "        \"utter_goodbye\": [\"Great, I'll go now. Bye bye\", \"bye bye\", \"Goodbye!\"],\n",
    "        \"utter_default\": [\"Sorry, I didn't quite follow\"],\n",
    "        \"utter_confirm\": [\"Got it\", \"Gotcha\", \"Your order is confirmed now\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_map = {\n",
    "    \"greet\": \"utter_greet\",\n",
    "    \"affirm\": \"utter_goodbye\",\n",
    "    \"deny\": \"utter_options\",\n",
    "    \"inform\": \"utter_confirm\",\n",
    "    \"default\": \"utter_default\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def get_bot_response(bot_response_map, bot_templates, intent):\n",
    "    if intent not in list(response_map):\n",
    "        intent = \"default\"\n",
    "    select_template = bot_response_map[intent]\n",
    "    templates = bot_templates[select_template]\n",
    "    return random.choice(templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Got it'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_intent = get_intent(embed, data, \"i want indian food\")\n",
    "get_bot_response(response_map, templates, user_intent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Better Response Personalisation?**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text : 'hey', intent: greet, bot: Hey! How you doin'? \n",
      "text : 'i am looking for italian food', intent: inform, bot: Gotcha\n",
      "text : 'not for me', intent: deny, bot: ok, let me check some more\n",
      "text : 'ok, this is good', intent: affirm, bot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "for text in [\"hey\",\"i am looking for italian food\",\"not for me\", \"ok, this is good\"]:\n",
    "    user_intent = get_intent(embed, data, text)\n",
    "    bot_reply = get_bot_response(response_map, templates, user_intent)\n",
    "    print(f\"text : '{text}', intent: {user_intent}, bot: {bot_reply}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastAI",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
