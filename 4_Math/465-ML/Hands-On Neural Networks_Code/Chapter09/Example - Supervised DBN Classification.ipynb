{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'deep-belief-network'...\n",
      "remote: Enumerating objects: 789, done.\u001b[K\n",
      "remote: Total 789 (delta 0), reused 0 (delta 0), pack-reused 789\u001b[K\n",
      "Receiving objects: 100% (789/789), 178.18 KiB | 0 bytes/s, done.\n",
      "Resolving deltas: 100% (457/457), done.\n",
      "Checking connectivity... done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/albertbup/deep-belief-network/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dbn.tensorflow import SupervisedDBNClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.classification import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "X = np.array(data.drop(['label'], axis=1))\n",
    "Y = np.array(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X = ss.fit_transform(X)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 390502134.398086\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 4783035232.880865\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 22433036841.961956\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 70255701108.889267\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 179942337228.445953\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 361195065458.535217\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 687980069524.817139\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 1193635709442.773193\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 1893320583123.591309\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 2905386764533.201660\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 4458335135889636018211520512.000000\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 234816424372552893935126577152.000000\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 356718421614462163809462124544.000000\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 419710861487029483415348969472.000000\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 436567669768553517141511372800.000000\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 445278433646059275831209885696.000000\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 425572036091976109311618187264.000000\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 435540460611199711914628218880.000000\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 424147883697538213186652602368.000000\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 401739121368365857932813795328.000000\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 0 finished \tANN training loss nan\n",
      ">> Epoch 1 finished \tANN training loss nan\n",
      ">> Epoch 2 finished \tANN training loss nan\n",
      ">> Epoch 3 finished \tANN training loss nan\n",
      ">> Epoch 4 finished \tANN training loss nan\n",
      ">> Epoch 5 finished \tANN training loss nan\n",
      ">> Epoch 6 finished \tANN training loss nan\n",
      ">> Epoch 7 finished \tANN training loss nan\n",
      ">> Epoch 8 finished \tANN training loss nan\n",
      ">> Epoch 9 finished \tANN training loss nan\n",
      ">> Epoch 10 finished \tANN training loss nan\n",
      ">> Epoch 11 finished \tANN training loss nan\n",
      ">> Epoch 12 finished \tANN training loss nan\n",
      ">> Epoch 13 finished \tANN training loss nan\n",
      ">> Epoch 14 finished \tANN training loss nan\n",
      ">> Epoch 15 finished \tANN training loss nan\n",
      ">> Epoch 16 finished \tANN training loss nan\n",
      ">> Epoch 17 finished \tANN training loss nan\n",
      ">> Epoch 18 finished \tANN training loss nan\n",
      ">> Epoch 19 finished \tANN training loss nan\n",
      ">> Epoch 20 finished \tANN training loss nan\n",
      ">> Epoch 21 finished \tANN training loss nan\n",
      ">> Epoch 22 finished \tANN training loss nan\n",
      ">> Epoch 23 finished \tANN training loss nan\n",
      ">> Epoch 24 finished \tANN training loss nan\n",
      ">> Epoch 25 finished \tANN training loss nan\n",
      ">> Epoch 26 finished \tANN training loss nan\n",
      ">> Epoch 27 finished \tANN training loss nan\n",
      ">> Epoch 28 finished \tANN training loss nan\n",
      ">> Epoch 29 finished \tANN training loss nan\n",
      ">> Epoch 30 finished \tANN training loss nan\n",
      ">> Epoch 31 finished \tANN training loss nan\n",
      ">> Epoch 32 finished \tANN training loss nan\n",
      ">> Epoch 33 finished \tANN training loss nan\n",
      ">> Epoch 34 finished \tANN training loss nan\n",
      ">> Epoch 35 finished \tANN training loss nan\n",
      ">> Epoch 36 finished \tANN training loss nan\n",
      ">> Epoch 37 finished \tANN training loss nan\n",
      ">> Epoch 38 finished \tANN training loss nan\n",
      ">> Epoch 39 finished \tANN training loss nan\n",
      ">> Epoch 40 finished \tANN training loss nan\n",
      ">> Epoch 41 finished \tANN training loss nan\n",
      ">> Epoch 42 finished \tANN training loss nan\n",
      ">> Epoch 43 finished \tANN training loss nan\n",
      ">> Epoch 44 finished \tANN training loss nan\n",
      ">> Epoch 45 finished \tANN training loss nan\n",
      ">> Epoch 46 finished \tANN training loss nan\n",
      ">> Epoch 47 finished \tANN training loss nan\n",
      ">> Epoch 48 finished \tANN training loss nan\n",
      ">> Epoch 49 finished \tANN training loss nan\n",
      ">> Epoch 50 finished \tANN training loss nan\n",
      ">> Epoch 51 finished \tANN training loss nan\n",
      ">> Epoch 52 finished \tANN training loss nan\n",
      ">> Epoch 53 finished \tANN training loss nan\n",
      ">> Epoch 54 finished \tANN training loss nan\n",
      ">> Epoch 55 finished \tANN training loss nan\n",
      ">> Epoch 56 finished \tANN training loss nan\n",
      ">> Epoch 57 finished \tANN training loss nan\n",
      ">> Epoch 58 finished \tANN training loss nan\n",
      ">> Epoch 59 finished \tANN training loss nan\n",
      ">> Epoch 60 finished \tANN training loss nan\n",
      ">> Epoch 61 finished \tANN training loss nan\n",
      ">> Epoch 62 finished \tANN training loss nan\n",
      ">> Epoch 63 finished \tANN training loss nan\n",
      ">> Epoch 64 finished \tANN training loss nan\n",
      ">> Epoch 65 finished \tANN training loss nan\n",
      ">> Epoch 66 finished \tANN training loss nan\n",
      ">> Epoch 67 finished \tANN training loss nan\n",
      ">> Epoch 68 finished \tANN training loss nan\n",
      ">> Epoch 69 finished \tANN training loss nan\n",
      ">> Epoch 70 finished \tANN training loss nan\n",
      ">> Epoch 71 finished \tANN training loss nan\n",
      ">> Epoch 72 finished \tANN training loss nan\n",
      ">> Epoch 73 finished \tANN training loss nan\n",
      ">> Epoch 74 finished \tANN training loss nan\n",
      ">> Epoch 75 finished \tANN training loss nan\n",
      ">> Epoch 76 finished \tANN training loss nan\n",
      ">> Epoch 77 finished \tANN training loss nan\n",
      ">> Epoch 78 finished \tANN training loss nan\n",
      ">> Epoch 79 finished \tANN training loss nan\n",
      ">> Epoch 80 finished \tANN training loss nan\n",
      ">> Epoch 81 finished \tANN training loss nan\n",
      ">> Epoch 82 finished \tANN training loss nan\n",
      ">> Epoch 83 finished \tANN training loss nan\n",
      ">> Epoch 84 finished \tANN training loss nan\n",
      ">> Epoch 85 finished \tANN training loss nan\n",
      ">> Epoch 86 finished \tANN training loss nan\n",
      ">> Epoch 87 finished \tANN training loss nan\n",
      ">> Epoch 88 finished \tANN training loss nan\n",
      ">> Epoch 89 finished \tANN training loss nan\n",
      ">> Epoch 90 finished \tANN training loss nan\n",
      ">> Epoch 91 finished \tANN training loss nan\n",
      ">> Epoch 92 finished \tANN training loss nan\n",
      ">> Epoch 93 finished \tANN training loss nan\n",
      ">> Epoch 94 finished \tANN training loss nan\n",
      ">> Epoch 95 finished \tANN training loss nan\n",
      ">> Epoch 96 finished \tANN training loss nan\n",
      ">> Epoch 97 finished \tANN training loss nan\n",
      ">> Epoch 98 finished \tANN training loss nan\n",
      ">> Epoch 99 finished \tANN training loss nan\n",
      "[END] Fine tuning step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SupervisedDBNClassification(batch_size=32, dropout_p=0.2,\n",
       "              idx_to_label_map={0: 6, 1: 4, 2: 2, 3: 3, 4: 1, 5: 8, 6: 5, 7: 7, 8: 9, 9: 0},\n",
       "              l2_regularization=1.0,\n",
       "              label_to_idx_map={6: 0, 4: 1, 2: 2, 3: 3, 1: 4, 8: 5, 5: 6, 7: 7, 9: 8, 0: 9},\n",
       "              learning_rate=0.1, n_iter_backprop=100, verbose=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = SupervisedDBNClassification(hidden_layers_structure =[256, 256],\n",
    "learning_rate_rbm=0.05,\n",
    "learning_rate=0.1,\n",
    "n_epochs_rbm=10,\n",
    "n_iter_backprop=100,\n",
    "batch_size=32,\n",
    "activation_function='relu',\n",
    "dropout_p=0.2)\n",
    "\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
