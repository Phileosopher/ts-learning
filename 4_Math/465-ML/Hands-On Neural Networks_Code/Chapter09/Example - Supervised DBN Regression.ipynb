{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.regression import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from dbn.tensorflow import SupervisedDBNRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Boston dataset\n",
    "boston = load_boston()\n",
    "# Define x and y variables\n",
    "x, y = boston.data, boston.target\n",
    "# Split dataset between train and test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "x_train = min_max_scaler.fit_transform(x_train)\n",
    "x_test = min_max_scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 1.812507\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 0.985429\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 0.683600\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 0.630324\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 0.615268\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 0.605893\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 0.595044\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 0.585918\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 0.574277\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 0.560272\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 0.547976\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 0.532192\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 0.518768\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 0.503692\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 0.490132\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 0.474697\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 0.459180\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 0.447271\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 0.432835\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 0.418749\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 0 finished \tANN training loss 57.618561\n",
      ">> Epoch 1 finished \tANN training loss 78.349701\n",
      ">> Epoch 2 finished \tANN training loss 83.616455\n",
      ">> Epoch 3 finished \tANN training loss 39.324661\n",
      ">> Epoch 4 finished \tANN training loss 23.137484\n",
      ">> Epoch 5 finished \tANN training loss 20.994768\n",
      ">> Epoch 6 finished \tANN training loss 36.820702\n",
      ">> Epoch 7 finished \tANN training loss 63.649860\n",
      ">> Epoch 8 finished \tANN training loss 46.898960\n",
      ">> Epoch 9 finished \tANN training loss 17.822666\n",
      ">> Epoch 10 finished \tANN training loss 32.946739\n",
      ">> Epoch 11 finished \tANN training loss 16.790699\n",
      ">> Epoch 12 finished \tANN training loss 16.894501\n",
      ">> Epoch 13 finished \tANN training loss 19.909561\n",
      ">> Epoch 14 finished \tANN training loss 16.489605\n",
      ">> Epoch 15 finished \tANN training loss 15.921248\n",
      ">> Epoch 16 finished \tANN training loss 16.748348\n",
      ">> Epoch 17 finished \tANN training loss 18.303335\n",
      ">> Epoch 18 finished \tANN training loss 21.847008\n",
      ">> Epoch 19 finished \tANN training loss 25.747831\n",
      ">> Epoch 20 finished \tANN training loss 15.466467\n",
      ">> Epoch 21 finished \tANN training loss 32.374710\n",
      ">> Epoch 22 finished \tANN training loss 21.094011\n",
      ">> Epoch 23 finished \tANN training loss 14.996764\n",
      ">> Epoch 24 finished \tANN training loss 25.202799\n",
      ">> Epoch 25 finished \tANN training loss 15.411875\n",
      ">> Epoch 26 finished \tANN training loss 14.691759\n",
      ">> Epoch 27 finished \tANN training loss 22.579388\n",
      ">> Epoch 28 finished \tANN training loss 16.890411\n",
      ">> Epoch 29 finished \tANN training loss 13.351670\n",
      ">> Epoch 30 finished \tANN training loss 18.044392\n",
      ">> Epoch 31 finished \tANN training loss 13.144643\n",
      ">> Epoch 32 finished \tANN training loss 12.890000\n",
      ">> Epoch 33 finished \tANN training loss 18.816439\n",
      ">> Epoch 34 finished \tANN training loss 17.499903\n",
      ">> Epoch 35 finished \tANN training loss 14.646725\n",
      ">> Epoch 36 finished \tANN training loss 20.009703\n",
      ">> Epoch 37 finished \tANN training loss 17.429331\n",
      ">> Epoch 38 finished \tANN training loss 12.717115\n",
      ">> Epoch 39 finished \tANN training loss 12.541926\n",
      ">> Epoch 40 finished \tANN training loss 12.606025\n",
      ">> Epoch 41 finished \tANN training loss 12.632132\n",
      ">> Epoch 42 finished \tANN training loss 12.445956\n",
      ">> Epoch 43 finished \tANN training loss 13.447710\n",
      ">> Epoch 44 finished \tANN training loss 15.836372\n",
      ">> Epoch 45 finished \tANN training loss 12.490176\n",
      ">> Epoch 46 finished \tANN training loss 17.750566\n",
      ">> Epoch 47 finished \tANN training loss 17.646303\n",
      ">> Epoch 48 finished \tANN training loss 15.479263\n",
      ">> Epoch 49 finished \tANN training loss 16.170170\n",
      ">> Epoch 50 finished \tANN training loss 14.072885\n",
      ">> Epoch 51 finished \tANN training loss 11.938646\n",
      ">> Epoch 52 finished \tANN training loss 14.127629\n",
      ">> Epoch 53 finished \tANN training loss 13.729725\n",
      ">> Epoch 54 finished \tANN training loss 16.498976\n",
      ">> Epoch 55 finished \tANN training loss 13.177352\n",
      ">> Epoch 56 finished \tANN training loss 11.321278\n",
      ">> Epoch 57 finished \tANN training loss 12.605772\n",
      ">> Epoch 58 finished \tANN training loss 12.289769\n",
      ">> Epoch 59 finished \tANN training loss 12.204030\n",
      ">> Epoch 60 finished \tANN training loss 11.009563\n",
      ">> Epoch 61 finished \tANN training loss 11.104411\n",
      ">> Epoch 62 finished \tANN training loss 30.409718\n",
      ">> Epoch 63 finished \tANN training loss 15.135267\n",
      ">> Epoch 64 finished \tANN training loss 11.330920\n",
      ">> Epoch 65 finished \tANN training loss 11.175768\n",
      ">> Epoch 66 finished \tANN training loss 12.056725\n",
      ">> Epoch 67 finished \tANN training loss 14.824623\n",
      ">> Epoch 68 finished \tANN training loss 11.064104\n",
      ">> Epoch 69 finished \tANN training loss 11.321557\n",
      ">> Epoch 70 finished \tANN training loss 21.173920\n",
      ">> Epoch 71 finished \tANN training loss 18.152477\n",
      ">> Epoch 72 finished \tANN training loss 10.886406\n",
      ">> Epoch 73 finished \tANN training loss 14.212158\n",
      ">> Epoch 74 finished \tANN training loss 10.429821\n",
      ">> Epoch 75 finished \tANN training loss 16.190269\n",
      ">> Epoch 76 finished \tANN training loss 10.724752\n",
      ">> Epoch 77 finished \tANN training loss 15.567206\n",
      ">> Epoch 78 finished \tANN training loss 10.666305\n",
      ">> Epoch 79 finished \tANN training loss 10.460849\n",
      ">> Epoch 80 finished \tANN training loss 10.412962\n",
      ">> Epoch 81 finished \tANN training loss 10.161211\n",
      ">> Epoch 82 finished \tANN training loss 13.825795\n",
      ">> Epoch 83 finished \tANN training loss 18.983755\n",
      ">> Epoch 84 finished \tANN training loss 10.080638\n",
      ">> Epoch 85 finished \tANN training loss 20.164360\n",
      ">> Epoch 86 finished \tANN training loss 10.957257\n",
      ">> Epoch 87 finished \tANN training loss 10.241315\n",
      ">> Epoch 88 finished \tANN training loss 10.274383\n",
      ">> Epoch 89 finished \tANN training loss 14.106511\n",
      ">> Epoch 90 finished \tANN training loss 11.366417\n",
      ">> Epoch 91 finished \tANN training loss 10.202339\n",
      ">> Epoch 92 finished \tANN training loss 11.485312\n",
      ">> Epoch 93 finished \tANN training loss 9.827599\n",
      ">> Epoch 94 finished \tANN training loss 10.350854\n",
      ">> Epoch 95 finished \tANN training loss 11.584213\n",
      ">> Epoch 96 finished \tANN training loss 10.741761\n",
      ">> Epoch 97 finished \tANN training loss 11.675300\n",
      ">> Epoch 98 finished \tANN training loss 10.426038\n",
      ">> Epoch 99 finished \tANN training loss 11.784066\n",
      "[END] Fine tuning step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SupervisedDBNRegression(batch_size=20, dropout_p=0, l2_regularization=1.0,\n",
       "            learning_rate=0.01, n_iter_backprop=100, verbose=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = SupervisedDBNRegression(hidden_layers_structure=[100],\n",
    "                                    learning_rate_rbm=0.01,\n",
    "                                    learning_rate=0.01,\n",
    "                                    n_epochs_rbm=20,\n",
    "                                    n_iter_backprop=100,\n",
    "                                    batch_size=20,\n",
    "                                    activation_function='relu')\n",
    "regressor.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.92020576638113"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = regressor.predict(x_test)\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
