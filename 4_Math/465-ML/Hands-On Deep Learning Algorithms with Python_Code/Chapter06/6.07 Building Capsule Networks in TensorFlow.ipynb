{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Capsule Networks in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will learn how to implement capsule networks in tensorflow. We will use our favorite MNIST dataset to learn how capsule networks recognize the handwritten digits. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the libraries\n",
    "\n",
    "Import the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "\n",
    "Load the MNIST dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"data/mnist\",one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the batch size and epsilon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "epsilon = 1e-9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Squash function\n",
    "\n",
    "We learned that the squash function converts the length of the vector into probability and it is given as,\n",
    "\n",
    "$$\\vec{v}_{j}=\\frac{\\left\\|\\vec{s}_{j}\\right\\|^{2}}{1+\\left\\|\\vec{s}_{j}\\right\\|^{2}} \\frac{\\vec{s}_{j}}{\\left\\|\\vec{s}_{j}\\right\\|} \\tag{1}$$\n",
    "\n",
    "\n",
    "The above Squash function can be defined as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(sj):\n",
    "    \n",
    "    sj_norm = tf.reduce_sum(tf.square(sj), -2, keep_dims=True)\n",
    "    scalar_factor = sj_norm / (1 + sj_norm) / tf.sqrt(sj_norm + epsilon)\n",
    "\n",
    "    vj = scalar_factor * sj  \n",
    "\n",
    "    return vj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Dynamic Routing Algorithm\n",
    "\n",
    "\n",
    "Now we will see how the dynamic routing algorithm is implemented. We use variable names as same notations we learned in the dynamic routing algorithm so that we can easily follow the steps. You can also check the comments on each line of code for better understanding.\n",
    "\n",
    "First, define the function as dynamic_routing which takes the ui - previous capsules, bij - coupling coefficients and num_routing - number of routing iterations as inputs and returns the activity vector vj as an output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_routing(ui, bij, num_routing=10):\n",
    "    \n",
    "    #initialize weights wij by drawing from a random normal distribution\n",
    "    wij = tf.get_variable('Weight', shape=(1, 1152, 160, 8, 1), dtype=tf.float32, \n",
    "                                  initializer=tf.random_normal_initializer(0.01))\n",
    "\n",
    "    #initialize biases with a constant value\n",
    "    biases = tf.get_variable('bias', shape=(1, 1, 10, 16, 1))\n",
    "    \n",
    "    #define the primary capsules: (tf.tile replicates the tensor n times)\n",
    "    ui = tf.tile(ui, [1, 1, 160, 1, 1])\n",
    "\n",
    "    #compute the prediction vector\n",
    "    u_hat = tf.reduce_sum(wij * ui, axis=3, keep_dims=True)\n",
    "    \n",
    "    #reshape the prediction vector\n",
    "    u_hat = tf.reshape(u_hat, shape=[-1, 1152, 10, 16, 1])\n",
    "\n",
    "    #stop gradient computation in the prediction vector\n",
    "    u_hat_stopped = tf.stop_gradient(u_hat, name='stop_gradient')\n",
    "\n",
    "    #perform dynamic routing for number of routing iterations\n",
    "    for r in range(num_routing):\n",
    "    \n",
    "        #refer dynamic routing algorithm in the book for the detailed explanation on the following steps\n",
    "        with tf.variable_scope('iter_' + str(r)):\n",
    "               \n",
    "            #step 1\n",
    "            cij = tf.nn.softmax(bij, dim=2)\n",
    "            \n",
    "            #step 2\n",
    "            if r == num_routing - 1:\n",
    "\n",
    "                sj = tf.multiply(cij, u_hat)\n",
    "\n",
    "                sj = tf.reduce_sum(sj, axis=1, keep_dims=True) + biases\n",
    "\n",
    "                vj = squash(sj)\n",
    "\n",
    "            elif r < num_routing - 1: \n",
    "\n",
    "                sj = tf.multiply(cij, u_hat_stopped)\n",
    "\n",
    "                sj = tf.reduce_sum(sj, axis=1, keep_dims=True) + biases\n",
    "\n",
    "                vj = squash(sj)\n",
    "\n",
    "                vj_tiled = tf.tile(vj, [1, 1152, 1, 1, 1])\n",
    "\n",
    "                coupling_coeff = tf.reduce_sum(u_hat_stopped * vj_tiled, axis=3, keep_dims=True)\n",
    "\n",
    "                #step 3\n",
    "                bij += coupling_coeff\n",
    "\n",
    "    return vj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Primary capsules and Digit capsules\n",
    "\n",
    "\n",
    "Compute primary capsules which extracts the basic features and digit capsules which recognizes the digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default() as g:\n",
    "     \n",
    "    #placeholders for the input and output\n",
    "    x = tf.placeholder(tf.float32, [batch_size, 784])\n",
    "    y = tf.placeholder(tf.float32, [batch_size,10])\n",
    "    \n",
    "    #reshape the input x\n",
    "    x_image = tf.reshape(x, [-1,28,28,1])\n",
    "\n",
    "    #perform the convolutional operation and get the convolutional input,\n",
    "    with tf.name_scope('convolutional_input'):\n",
    "        input_data = tf.contrib.layers.conv2d(inputs=x_image, num_outputs=256, \n",
    "                                              kernel_size=9, padding='valid')\n",
    "        \n",
    "    \n",
    "    #compute the primary capsules which extract the basic features such as edges.    \n",
    "    #first, compute the capsules using convolution operation:\n",
    "    capsules = []\n",
    "\n",
    "    for i in range(8):\n",
    "\n",
    "        with tf.name_scope('capsules_' + str(i)):\n",
    "           \n",
    "            #convolution operation\n",
    "            output = tf.contrib.layers.conv2d(inputs=input_data, num_outputs=32,kernel_size=9,\n",
    "                                              stride=2, padding='valid')\n",
    "            \n",
    "            #reshape the output\n",
    "            output = tf.reshape(output, [batch_size, -1, 1, 1])\n",
    "            \n",
    "            #store the output which is capsule in the capsules list\n",
    "            capsules.append(output)\n",
    "    \n",
    "    #concatenate all the capsules and form the primary capsule    \n",
    "    primary_capsule = tf.concat(capsules, axis=2)\n",
    "    \n",
    "    #squash the primary capsule and get the probability i.e apply squash function and get the probability\n",
    "    primary_capsule = squash(primary_capsule)\n",
    "    \n",
    "\n",
    "    #compute digit capsules using dynamic routing\n",
    "    with tf.name_scope('dynamic_routing'):\n",
    "        \n",
    "        #reshape the primary capsule\n",
    "        outputs = tf.reshape(primary_capsule, shape=(batch_size, -1, 1, primary_capsule.shape[-2].value, 1))\n",
    "        \n",
    "        #initialize bij with 0s\n",
    "        bij = tf.constant(np.zeros([1, primary_capsule.shape[1].value, 10, 1, 1], dtype=np.float32))\n",
    "        \n",
    "        #compute the digit capsules using dynamic routing algorithm which takes \n",
    "        #the reshaped primary capsules and bij as inputs and returns the activity vector \n",
    "        digit_capsules = dynamic_routing(outputs, bij)\n",
    "   \n",
    "    digit_capsules = tf.squeeze(digit_capsules, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking the Digit Capsule\n",
    "\n",
    "Why do we need to mask the digit capsule? We learned that in order to make sure that the network has learned the important features, we use a three-layer network called decoder network which tries to reconstruct the original image from the digit capsules. If the decoder is able to reconstruct the image successfully from the digit capsules then it means the network has learned important features of the image else the network has not learned the correct features of the image.\n",
    "\n",
    "The digit capsules contain the activity vector for all the digits. But the decoder wants to reconstruct only the given input digit (input image). So, we mask out the activity vector of all the digits except for the correct digit. Then we use this masked digit capsule to reconstruct the given input image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default() as g:\n",
    "    with tf.variable_scope('Masking'):\n",
    "        \n",
    "        # select the activity vector of given input image using the actual label y and mask out others\n",
    "        masked_v = tf.multiply(tf.squeeze(digit_capsules), tf.reshape(y, (-1, 10, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Decoder\n",
    "\n",
    "\n",
    "Define the decoder network for reconstructing the image. It consists of three fully connected networks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default() as g:\n",
    "    \n",
    "    with tf.name_scope('Decoder'):\n",
    "        \n",
    "        #masked digit capsule\n",
    "        v_j = tf.reshape(masked_v, shape=(batch_size, -1))\n",
    "        \n",
    "        #first fully connected layer \n",
    "        fc1 = tf.contrib.layers.fully_connected(v_j, num_outputs=512)\n",
    "           \n",
    "        #second fully connected layer\n",
    "        fc2 = tf.contrib.layers.fully_connected(fc1, num_outputs=1024)\n",
    "\n",
    "        #reconstructed image\n",
    "        reconstructed_image = tf.contrib.layers.fully_connected(fc2, num_outputs=784, activation_fn=tf.sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Accuracy\n",
    "\n",
    "Now, we compute the accuracy of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default() as g:\n",
    "    with tf.variable_scope('accuracy'):\n",
    "        \n",
    "        #compute the length of each activity vector in the digit capsule \n",
    "        v_length = tf.sqrt(tf.reduce_sum(tf.square(digit_capsules), axis=2, keep_dims=True) + epsilon)\n",
    "       \n",
    "        #apply softmax to the length and get the probabilities\n",
    "        softmax_v = tf.nn.softmax(v_length, dim=1)\n",
    "       \n",
    "        #select the index which got the highest probability this will give us the predicted digit \n",
    "        argmax_idx = tf.to_int32(tf.argmax(softmax_v, axis=1))    \n",
    "        predicted_digit = tf.reshape(argmax_idx, shape=(batch_size, ))\n",
    "        \n",
    "        #compute the accuracy\n",
    "        actual_digit = tf.to_int32(tf.argmax(y, axis=1))\n",
    "        \n",
    "        correct_pred = tf.equal(predicted_digit,actual_digit)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Loss\n",
    "\n",
    "As we now, we compute two types of loss - Margin loss and reconstruction loss\n",
    "\n",
    "Margin loss $L_k$ for a digit (class) $k$ is given as: \n",
    "\n",
    "$$ L_{k}=T_{k} \\max \\left(0, m^{+}-\\left\\|v_{k}\\right\\|\\right)^{2}+\\lambda\\left(1-T_{k}\\right) \\max \\left(0,\\left\\|v_{k}\\right\\|-m^{-}\\right)^{2} \\tag{2} $$\n",
    "\n",
    "The total margin loss is the sum of the loss of all classes and is given as:\n",
    "\n",
    "$$ \\operatorname{Margin Loss} =\\sum_{k} L_{k} \\tag{3} $$\n",
    "\n",
    "Reconstruction loss is given as a squared difference between the reconstructed and original\n",
    "image: \n",
    "\n",
    "$$ \\operatorname{Reconstruction Loss} =  (\\text { Reconstructed Image }-\\text { Original Image })^{2} \\tag{4}$$\n",
    "\n",
    "Thus the final loss is given as:\n",
    "\n",
    "$$ \\operatorname{Loss} = \\operatorname{Margin Loss} + \\operatorname{alpha} * \\operatorname{Reconstruction Loss} \\tag{5} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_ = 0.5\n",
    "alpha = 0.0005\n",
    "\n",
    "with graph.as_default() as g:\n",
    "\n",
    "    #margin loss\n",
    "    max_left = tf.square(tf.maximum(0.,0.9 - v_length))\n",
    "    max_right = tf.square(tf.maximum(0., v_length - 0.1))\n",
    "\n",
    "    T_k = y\n",
    "    \n",
    "    #compute margin loss L_k for class k as given in (2)\n",
    "    L_k = T_k * max_left + lambda_ * (1 - T_k) * max_right\n",
    "    \n",
    "    #compute total margin as given in refer equation (3)\n",
    "    margin_loss = tf.reduce_mean(tf.reduce_sum(L_k, axis=1))\n",
    "    \n",
    "    #reshape and get the original image\n",
    "    original_image = tf.reshape(x, shape=(batch_size, -1))\n",
    "    \n",
    "    #compute reconstruction loss as shown in (4)\n",
    "    squared = tf.square(reconstructed_image - original_image)\n",
    "    reconstruction_loss = tf.reduce_mean(squared)\n",
    "\n",
    "    #compute total loss which is the weighted sum of margin and reconstructed loss as shown in (5)\n",
    "    total_loss = margin_loss + alpha * reconstruction_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize loss\n",
    "\n",
    "Minimize the loss using Adam Optimizer,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default() as g:\n",
    "    optimizer = tf.train.AdamOptimizer(0.0001).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training the Capsule Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the number of epochs and number of steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "num_steps = int(len(mnist.train.images)/batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now start the tensorflow session and perform training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, iteration:0, Loss:0.553201019764 Accuracy: 0.140000000596\n",
      "Epoch: 0, iteration:10, Loss:0.543244898319 Accuracy: 0.119999997318\n",
      "Epoch: 0, iteration:20, Loss:0.531144499779 Accuracy: 0.119999997318\n",
      "Epoch: 0, iteration:30, Loss:0.526307284832 Accuracy: 0.119999997318\n",
      "Epoch: 0, iteration:40, Loss:0.526460289955 Accuracy: 0.140000000596\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for iteration in range(num_steps):\n",
    "            batch_data, batch_labels = mnist.train.next_batch(batch_size)\n",
    "            feed_dict = {x : batch_data, y : batch_labels}\n",
    "     \n",
    "            _, loss, acc = sess.run([optimizer, total_loss, accuracy], feed_dict=feed_dict)\n",
    "\n",
    "            if iteration%10 == 0:\n",
    "                print('Epoch: {}, iteration:{}, Loss:{} Accuracy: {}'.format(epoch,iteration,loss,acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just learned how capsule network works step by step and how to build capsule network in tensorflow, in the next chapter we will study in detail about the various algorithms that are used for learning the text representations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
